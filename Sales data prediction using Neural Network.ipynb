{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales data prediction using Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are provided sales data of videos games. For each game we have several <br>\n",
    "features which give different information. <br>\n",
    "We have to predict the total earning of the video games from the data using NN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic_rating</th>\n",
       "      <th>is_action</th>\n",
       "      <th>is_exclusive_to_us</th>\n",
       "      <th>is_portable</th>\n",
       "      <th>is_role_playing</th>\n",
       "      <th>is_sequel</th>\n",
       "      <th>is_sports</th>\n",
       "      <th>suitable_for_kids</th>\n",
       "      <th>total_earnings</th>\n",
       "      <th>unit_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132717</td>\n",
       "      <td>59.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83407</td>\n",
       "      <td>49.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62423</td>\n",
       "      <td>49.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>69889</td>\n",
       "      <td>39.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161382</td>\n",
       "      <td>59.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   critic_rating  is_action  is_exclusive_to_us  is_portable  is_role_playing  \\\n",
       "0            3.5          1                   0            1                0   \n",
       "1            4.5          0                   0            0                0   \n",
       "2            3.0          0                   0            0                0   \n",
       "3            4.5          1                   0            0                0   \n",
       "4            4.0          1                   0            1                0   \n",
       "\n",
       "   is_sequel  is_sports  suitable_for_kids  total_earnings  unit_price  \n",
       "0          1          0                  0          132717       59.99  \n",
       "1          1          1                  0           83407       49.99  \n",
       "2          1          1                  0           62423       49.99  \n",
       "3          0          0                  1           69889       39.99  \n",
       "4          1          0                  1          161382       59.99  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "\n",
    "train_data=pd.read_csv('sales_data_training.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ok so!we have 1000 rows and 10 columns Our target variable is total earning!\n",
    "\n",
    "But as can be seen the data is needs to be normalized becuase it is in different range\n",
    "keep in mind this is the trainig data. \n",
    "we will have our test data as well \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 1.        , 0.        , ..., 0.        , 0.37471396,\n",
       "        1.        ],\n",
       "       [0.83333333, 0.        , 0.        , ..., 0.        , 0.19242528,\n",
       "        0.5       ],\n",
       "       [0.33333333, 0.        , 0.        , ..., 0.        , 0.11485185,\n",
       "        0.5       ],\n",
       "       ...,\n",
       "       [0.83333333, 0.        , 1.        , ..., 0.        , 0.61007375,\n",
       "        1.        ],\n",
       "       [0.5       , 1.        , 1.        , ..., 1.        , 0.24626902,\n",
       "        0.        ],\n",
       "       [0.33333333, 1.        , 0.        , ..., 1.        , 0.21633242,\n",
       "        0.5       ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_training= scaler.fit_transform(train_data)\n",
    "scaled_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us import our test data now\n",
    "test_data = pd.read_csv('sales_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 1.        , 1.        , ..., 1.        , 0.79917931,\n",
       "        1.        ],\n",
       "       [0.16666667, 0.        , 0.        , ..., 0.        , 0.15750171,\n",
       "        1.        ],\n",
       "       [0.5       , 0.        , 0.        , ..., 0.        , 0.18970444,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [1.        , 1.        , 1.        , ..., 0.        , 0.41018835,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 1.        , ..., 0.        , 0.11162086,\n",
       "        0.        ],\n",
       "       [0.5       , 1.        , 0.        , ..., 0.        , 0.18022587,\n",
       "        0.5       ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize the test data as well but in the same parameters as the train data\n",
    "\n",
    "scaled_test = scaler.transform(test_data)  \n",
    "scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new pandas DataFrame objects from the scaled data\n",
    "scaled_training_df = pd.DataFrame(scaled_training, columns=train_data.columns.values)\n",
    "scaled_testing_df = pd.DataFrame(scaled_test, columns=test_data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" let us first separate our trainig samples and target variable\n",
    "into X and Y\"\"\"\n",
    "\n",
    "X = scaled_training_df.drop('total_earnings', axis=1).values\n",
    "Y = scaled_training_df[['total_earnings']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Model\n",
    "model1 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(Dense(50, input_dim=9, activation='relu'))\n",
    "model1.add(Dense(100, activation='relu'))\n",
    "model1.add(Dense(50, activation='relu'))\n",
    "model1.add(Dense(1,activation ='linear'))\n",
    "model1.compile(loss=\"mean_squared_error\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 50)                500       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,701\n",
      "Trainable params: 10,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 - 1s - loss: 0.0333 - 1s/epoch - 36ms/step\n",
      "Epoch 2/50\n",
      "32/32 - 0s - loss: 0.0057 - 79ms/epoch - 2ms/step\n",
      "Epoch 3/50\n",
      "32/32 - 0s - loss: 0.0014 - 79ms/epoch - 2ms/step\n",
      "Epoch 4/50\n",
      "32/32 - 0s - loss: 4.4083e-04 - 79ms/epoch - 2ms/step\n",
      "Epoch 5/50\n",
      "32/32 - 0s - loss: 2.0949e-04 - 80ms/epoch - 2ms/step\n",
      "Epoch 6/50\n",
      "32/32 - 0s - loss: 1.2857e-04 - 76ms/epoch - 2ms/step\n",
      "Epoch 7/50\n",
      "32/32 - 0s - loss: 1.1138e-04 - 76ms/epoch - 2ms/step\n",
      "Epoch 8/50\n",
      "32/32 - 0s - loss: 8.8157e-05 - 78ms/epoch - 2ms/step\n",
      "Epoch 9/50\n",
      "32/32 - 0s - loss: 8.7912e-05 - 77ms/epoch - 2ms/step\n",
      "Epoch 10/50\n",
      "32/32 - 0s - loss: 6.3165e-05 - 81ms/epoch - 3ms/step\n",
      "Epoch 11/50\n",
      "32/32 - 0s - loss: 6.8822e-05 - 76ms/epoch - 2ms/step\n",
      "Epoch 12/50\n",
      "32/32 - 0s - loss: 5.4480e-05 - 80ms/epoch - 3ms/step\n",
      "Epoch 13/50\n",
      "32/32 - 0s - loss: 3.7226e-05 - 75ms/epoch - 2ms/step\n",
      "Epoch 14/50\n",
      "32/32 - 0s - loss: 3.0077e-05 - 81ms/epoch - 3ms/step\n",
      "Epoch 15/50\n",
      "32/32 - 0s - loss: 3.1500e-05 - 81ms/epoch - 3ms/step\n",
      "Epoch 16/50\n",
      "32/32 - 0s - loss: 3.5011e-05 - 81ms/epoch - 3ms/step\n",
      "Epoch 17/50\n",
      "32/32 - 0s - loss: 2.7363e-05 - 82ms/epoch - 3ms/step\n",
      "Epoch 18/50\n",
      "32/32 - 0s - loss: 3.2216e-05 - 83ms/epoch - 3ms/step\n",
      "Epoch 19/50\n",
      "32/32 - 0s - loss: 2.5712e-05 - 82ms/epoch - 3ms/step\n",
      "Epoch 20/50\n",
      "32/32 - 0s - loss: 3.4721e-05 - 79ms/epoch - 2ms/step\n",
      "Epoch 21/50\n",
      "32/32 - 0s - loss: 3.5977e-05 - 82ms/epoch - 3ms/step\n",
      "Epoch 22/50\n",
      "32/32 - 0s - loss: 2.6731e-05 - 79ms/epoch - 2ms/step\n",
      "Epoch 23/50\n",
      "32/32 - 0s - loss: 3.5663e-05 - 80ms/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "32/32 - 0s - loss: 2.4666e-05 - 79ms/epoch - 2ms/step\n",
      "Epoch 25/50\n",
      "32/32 - 0s - loss: 2.4849e-05 - 77ms/epoch - 2ms/step\n",
      "Epoch 26/50\n",
      "32/32 - 0s - loss: 2.3018e-05 - 76ms/epoch - 2ms/step\n",
      "Epoch 27/50\n",
      "32/32 - 0s - loss: 2.5951e-05 - 81ms/epoch - 3ms/step\n",
      "Epoch 28/50\n",
      "32/32 - 0s - loss: 3.0559e-05 - 84ms/epoch - 3ms/step\n",
      "Epoch 29/50\n",
      "32/32 - 0s - loss: 3.2233e-05 - 83ms/epoch - 3ms/step\n",
      "Epoch 30/50\n",
      "32/32 - 0s - loss: 5.6185e-05 - 84ms/epoch - 3ms/step\n",
      "Epoch 31/50\n",
      "32/32 - 0s - loss: 4.5429e-05 - 85ms/epoch - 3ms/step\n",
      "Epoch 32/50\n",
      "32/32 - 0s - loss: 2.5919e-05 - 88ms/epoch - 3ms/step\n",
      "Epoch 33/50\n",
      "32/32 - 0s - loss: 2.7244e-05 - 89ms/epoch - 3ms/step\n",
      "Epoch 34/50\n",
      "32/32 - 0s - loss: 2.9249e-05 - 82ms/epoch - 3ms/step\n",
      "Epoch 35/50\n",
      "32/32 - 0s - loss: 3.3962e-05 - 78ms/epoch - 2ms/step\n",
      "Epoch 36/50\n",
      "32/32 - 0s - loss: 2.7849e-05 - 78ms/epoch - 2ms/step\n",
      "Epoch 37/50\n",
      "32/32 - 0s - loss: 5.7742e-05 - 78ms/epoch - 2ms/step\n",
      "Epoch 38/50\n",
      "32/32 - 0s - loss: 3.3949e-05 - 83ms/epoch - 3ms/step\n",
      "Epoch 39/50\n",
      "32/32 - 0s - loss: 2.0785e-05 - 79ms/epoch - 2ms/step\n",
      "Epoch 40/50\n",
      "32/32 - 0s - loss: 2.0729e-05 - 86ms/epoch - 3ms/step\n",
      "Epoch 41/50\n",
      "32/32 - 0s - loss: 1.8508e-05 - 81ms/epoch - 3ms/step\n",
      "Epoch 42/50\n",
      "32/32 - 0s - loss: 2.5192e-05 - 79ms/epoch - 2ms/step\n",
      "Epoch 43/50\n",
      "32/32 - 0s - loss: 3.7628e-05 - 82ms/epoch - 3ms/step\n",
      "Epoch 44/50\n",
      "32/32 - 0s - loss: 6.6118e-05 - 80ms/epoch - 2ms/step\n",
      "Epoch 45/50\n",
      "32/32 - 0s - loss: 1.0190e-04 - 81ms/epoch - 3ms/step\n",
      "Epoch 46/50\n",
      "32/32 - 0s - loss: 1.6026e-04 - 101ms/epoch - 3ms/step\n",
      "Epoch 47/50\n",
      "32/32 - 0s - loss: 2.5246e-04 - 88ms/epoch - 3ms/step\n",
      "Epoch 48/50\n",
      "32/32 - 0s - loss: 4.9432e-05 - 86ms/epoch - 3ms/step\n",
      "Epoch 49/50\n",
      "32/32 - 0s - loss: 3.7386e-05 - 88ms/epoch - 3ms/step\n",
      "Epoch 50/50\n",
      "32/32 - 0s - loss: 2.7976e-05 - 112ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26ccba77f10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model now\n",
    "model.fit(X,Y, epochs=50, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" To test our model on test data ! \n",
    "let us first separate our trainig samples and target variable\n",
    "into X and Y\"\"\"\n",
    "X_Test = scaled_testing_df.drop('total_earnings', axis=1).values\n",
    "Y_test = scaled_testing_df[['total_earnings']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = model.evaluate(X_Test, Y_test , verbose =0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean Square Error MSE for the test data is : 5.4205680498853326e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"The mean Square Error MSE for the test data is : {}\".format(test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great.. the error rate is very small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is predicting the test data perfectly.! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us use this model for prediction! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have completely new data now! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic_rating</th>\n",
       "      <th>is_action</th>\n",
       "      <th>is_exclusive_to_us</th>\n",
       "      <th>is_portable</th>\n",
       "      <th>is_role_playing</th>\n",
       "      <th>is_sequel</th>\n",
       "      <th>is_sports</th>\n",
       "      <th>suitable_for_kids</th>\n",
       "      <th>unit_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   critic_rating  is_action  is_exclusive_to_us  is_portable  is_role_playing  \\\n",
       "0            0.7        1.0                 1.0          1.0              0.0   \n",
       "\n",
       "   is_sequel  is_sports  suitable_for_kids  unit_price  \n",
       "0        1.0        0.0                1.0         0.8  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import completely new unseen data\n",
    "\n",
    "new_data = pd.read_csv('proposed_new_product.csv')\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make prediction\n",
    "prediction = model1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Earning prediction for proposed product is : $ 4779.554743725251\n"
     ]
    }
   ],
   "source": [
    "#reverse the scaling to see the prediction correctly\n",
    "\n",
    "prediction = prediction + 0.1159\n",
    "prediction = prediction / 0.000036968\n",
    "\n",
    "print(\"The Earning prediction for proposed product is : $ {}\".format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent for the proposed product the predicted earning is 4779.55 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to disk \n"
     ]
    }
   ],
   "source": [
    "\"\"\" let us save the model so as we get rid of training the model \n",
    "again \"\"\"\n",
    "\n",
    "model1.save(\"trained_model.h5\")   #the data will be stored in hda5 designed to store binary form\n",
    "\n",
    "print(\"Model saved to disk \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can load the saved model to use it again and again'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"\"\"You can load the saved model to use it again and again\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Now you have the model in \n",
    "your hand and you can use it ....!\"\"\"\n",
    "\n",
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way you can use the saved model and save your time ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
